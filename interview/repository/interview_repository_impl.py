import os
from typing import List, Dict

import openai

from interview.repository.interview_repository import InterviewRepository

class InterviewRepositoryImpl(InterviewRepository):
    openai.api_key = os.getenv("OPENAI_API_KEY")

    # ì²« ì§ˆë¬¸ ìƒì„±: ê³ ì¥ì§ˆë¬¸ "ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš”"
    def generateQuestions(
        self, interviewId: int, topic: str, experienceLevel: str, userToken: str
    ) -> str:
        print(f"[repository] Generating a single question from fine-tuned model for interviewId={interviewId}, userToken={userToken}")

        # ê³ ì •ì§ˆë¬¸
        # ìê¸°ì†Œê°œë¡œ ê°œì¸ì •ë³´ (ì´ë¦„ê³¼ ë‚˜ì´, í•™êµ ë“±ë“±) ì–»ê¸° -> ì´ ì •ë³´ëŠ” ë‹¤ìŒ ë‹µë³€ì— ì €ì¥
        return {
            "question": (
                f"{topic}ì˜ {experienceLevel}ë¶„ì•¼ì— ì§€ì›í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. "
                f"ì €ëŠ” AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ìš°ì„  ì§€ì›ìë¶„ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
            ),
            "questionId": 1  # ì‹¤ì œ DB ì €ì¥ ì‹œ IDë¡œ êµì²´
        }

    def generateFirstFollowup(
            self,
            interviewId: int,
            topic: str,
            experienceLevel: str,
            academicBackground: str,
            questionId: int,
            answerText: str,
            userToken: str
    ) -> list[str]:
        print(f" [repository] Generating intro follow-up questions for interviewId={interviewId},userToken={userToken}")

        prompt = (
            f"ë„ˆëŠ” IT ê¸°ì—…ì˜ ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ ë©´ì ‘ìì˜ ê¸°ë³¸ ì •ë³´ì™€ ìê¸°ì†Œê°œ ë‹µë³€ì„ ì°¸ê³ í•´, ì§ë¬´Â·ê²½ë ¥Â·í•™ë ¥ ë°°ê²½ê³¼ ê´€ë ¨ëœ ê¼¬ë¦¬ ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´ì¤˜.\n\n"
            f"[ì§ë¬´]: {topic}\n"
            f"[ê²½ë ¥]: {experienceLevel}\n"
            f"[í•™ë ¥ ë°°ê²½]: {academicBackground}\n"
            f"[ì²« ì§ˆë¬¸ ë²ˆí˜¸]: {questionId}\n"
            f"[ìê¸°ì†Œê°œ ë‹µë³€]: {answerText}\n\n"
            f"ìš”ì²­ì‚¬í•­:\n"
            f"- ì§ˆë¬¸ì€ ë°˜ë“œì‹œ **ì§§ê³  ëª…í™•í•œ í•œ ë¬¸ì¥**ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ\n"
            f"- **ë³µí•© ì§ˆë¬¸ ê¸ˆì§€**: í•˜ë‚˜ì˜ ì£¼ì œë§Œ ë¬¼ì–´ë³¼ ê²ƒ\n"
            f"- **ì„¤ëª…, ì¸ì‚¿ë§, ì¤„ë°”ê¿ˆ, ê¸°íƒ€ ë¬¸ì¥ í¬í•¨ ê¸ˆì§€**\n"
            f"- í•™ë ¥ ê´€ë ¨ ì§ˆë¬¸ ì‹œ, ëŒ€í•™ ì´ë¦„ì€ ë¬»ì§€ ë§ê³  ì „ê³µì´ë‚˜ ê³µë¶€í•œ ë‚´ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±\n"
            f"- **[í”„ë¡œì íŠ¸] ê´€ë ¨ ì§ˆë¬¸ì€ í•˜ì§€ ë§ ê²ƒ**\n"
            f"- ì¶œë ¥ì€ ì§ˆë¬¸ í•œ ë¬¸ì¥ë§Œ, ì•„ë¬´ ì„¤ëª…ë„ ë¶™ì´ì§€ ë§ê³  ì¶œë ¥í•  ê²ƒ"
        )

        # GPT í˜¸ì¶œ
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—­í• ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        result_text = response.choices[0].message.content.strip()
        questions = [q.strip() for q in result_text.split("\n") if q.strip()]

        print(f" [repository] Follow-up questions generated: {questions}")
        return questions

    # í”„ë¡œì íŠ¸ ì§ˆë¬¸: 3
    def generateProjectQuestion(
            self,
            interviewId: int,
            projectExperience: str,
            userToken: str
    ) -> list[str]:
        print(f"ğŸ“¡ [AI Server] Generating fixed project question for interviewId={interviewId}, userToken={userToken}")

        if projectExperience == "í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ":
            return ["ë‹¤ìŒ ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ì— ê´€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.\n ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ì…¨ë‚˜ìš”?"]
        else:
            return ["ë‹¤ìŒ ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ í˜¹ì€ ì§ë¬´ ê´€ë ¨ í™œë™ì— ê´€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.\n ì§ë¬´ì™€ ê´€ë ¨ëœ í™œë™ì„ í•´ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?"]


    # í”„ë¡œì íŠ¸ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±: 4
    def generateProjectFollowupQuestion(
            self,
            interviewId: int,
            topic: str,
            techStack: list[str],
            projectExperience: str,
            questionId: int,
            answerText: str,
            userToken: str,
    ) -> list[str]:

        print(f"ğŸ“¡ [AI Server] Generating 5 questions for interviewId={interviewId}, userToken={userToken}")

        # ğŸ¯ í”„ë¡¬í”„íŠ¸ ì •ì˜
        if projectExperience == "í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ":
            prompt = (
                "ë„ˆëŠ” ê¸°ìˆ  ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ ë©´ì ‘ìì˜ ì´ì „ ë‹µë³€ê³¼ ì§ˆë¬¸ IDë¥¼ ì°¸ê³ í•´ì„œ, ê·¸ì— ëŒ€í•œ ì‹¬í™” ì§ˆë¬¸ ë˜ëŠ” ê¼¬ë¦¬ ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´ì¤˜.\n\n"
                "[í”„ë¡œì íŠ¸ ê²½í—˜ ìœ ë¬´]: ìˆìŒ\n"
                "- ì´ì „ ì§ˆë¬¸ ID(questionId)ì™€ ë©´ì ‘ìì˜ ë‹µë³€(answerText)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ì„± ë†’ì€ í›„ì† ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì•¼ í•´.\n\n"
                "ìš”ì²­ì‚¬í•­:\n"
                "- ì§ˆë¬¸ì€ ë‹¨ í•˜ë‚˜ë§Œ ìƒì„±í•´.\n"
                "- ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ì§§ê³  ëª…í™•í•œ **í•œ ë¬¸ì¥**ìœ¼ë¡œ êµ¬ì„±í•  ê²ƒ.\n"
                "- ë³µí•© ì§ˆë¬¸ì€ ê¸ˆì§€í•˜ë©°, í•˜ë‚˜ì˜ ì£¼ì œë§Œ ë¬¼ì–´ë³¼ ê²ƒ.\n"
                "- ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ê³ , ì¤„ë°”ê¿ˆ ì—†ì´ ì¶œë ¥í•  ê²ƒ."
            )
        else:
            prompt = (
                "ë„ˆëŠ” ê¸°ìˆ  ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ ë©´ì ‘ìì˜ ì´ì „ ë‹µë³€ê³¼ ì§ˆë¬¸ IDë¥¼ ì°¸ê³ í•´ì„œ, ê·¸ì— ëŒ€í•œ ì‹¬í™” ì§ˆë¬¸ ë˜ëŠ” ê¼¬ë¦¬ ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´ì¤˜.\n\n"
                "[í”„ë¡œì íŠ¸ ê²½í—˜ ìœ ë¬´]: ì—†ìŒ\n"
                "- ì´ì „ ì§ˆë¬¸ ID(questionId)ì™€ ë©´ì ‘ìì˜ ë‹µë³€(answerText)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ì„± ë†’ì€ í›„ì† ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì•¼ í•´.\n\n"
                "ìš”ì²­ì‚¬í•­:\n"
                "- ì§ˆë¬¸ì€ ë‹¨ í•˜ë‚˜ë§Œ ìƒì„±í•´.\n"
                "- ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ì§§ê³  ëª…í™•í•œ **í•œ ë¬¸ì¥**ìœ¼ë¡œ êµ¬ì„±í•  ê²ƒ.\n"
                "- ë³µí•© ì§ˆë¬¸ì€ ê¸ˆì§€í•˜ë©°, í•˜ë‚˜ì˜ ì£¼ì œë§Œ ë¬¼ì–´ë³¼ ê²ƒ.\n"
                "- ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ê³ , ì¤„ë°”ê¿ˆ ì—†ì´ ì¶œë ¥í•  ê²ƒ."
            )

        # ğŸ“¡ GPT-4 í˜¸ì¶œ
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—­í• ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        result_text = response.choices[0].message.content.strip()
        questions = [q.strip() for q in result_text.split("\n") if q.strip()]

        return questions

    # ë©´ì ‘ ì¢…ë£Œ
    def end_interview(self,
                                session_id: str,
                                context: Dict[str, str],
                                questions: List[str],
                                answers: List[str]
                                ) -> Dict:
            # GPTë¥¼ ì‚¬ìš©í•´ ë©´ì ‘ ìš”ì•½ ìƒì„±
            joined_qna = "\n".join(
                [f"Q{i + 1}: {q}\nA{i + 1}: {a}" for i, (q, a) in enumerate(zip(questions, answers))]
            )

            context_summary = "\n".join([f"{k}: {v}" for k, v in context.items()])

            prompt = f"""
    ë„ˆëŠ” ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ëŠ” í•œ ì‚¬ìš©ìì˜ ì „ì²´ ë©´ì ‘ íë¦„ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ì´ì•¼.

    [ë©´ì ‘ì ì •ë³´]
    {context_summary}

    [ë©´ì ‘ ë‚´ìš©]
    {joined_qna}

    ë©´ì ‘ìì˜ ì „ì²´ì ì¸ íƒœë„, ê²½í—˜, ê°•ì ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ìš”ì•½ ë° í”¼ë“œë°±ì„ ìƒì„±í•´ì¤˜.
    """

            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ë©´ì ‘ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì£¼ëŠ” AI ì¸ì‚¬ë‹´ë‹¹ìì•¼."},
                    {"role": "user", "content": prompt.strip()}
                ],
                temperature=0.5
            )

            summary = response.choices[0].message["content"].strip()

            return {
                "session_id": session_id,
                "summary": summary,
                "message": "ë©´ì ‘ì´ ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "success": True
            }