import os
from typing import List, Dict

import openai

from interview.repository.interview_repository import InterviewRepository

class InterviewRepositoryImpl(InterviewRepository):
    openai.api_key = os.getenv("OPENAI_API_KEY")

    # ì²« ì§ˆë¬¸ ìƒì„±: ê³ ì¥ì§ˆë¬¸ "ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš”"
    def generateQuestions(
        self, interviewId: int, topic: str, experienceLevel: str, userToken: str
    ) -> str:
        print(f"[repository] Generating a single question from fine-tuned model for interviewId={interviewId}, userToken={userToken}")

        # ê³ ì •ì§ˆë¬¸
        # ìê¸°ì†Œê°œë¡œ ê°œì¸ì •ë³´ (ì´ë¦„ê³¼ ë‚˜ì´, í•™êµ ë“±ë“±) ì–»ê¸° -> ì´ ì •ë³´ëŠ” ë‹¤ìŒ ë‹µë³€ì— ì €ì¥
        return (
            f"{topic}ì˜ {experienceLevel}ë¶„ì•¼ì— ì§€ì›í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. "
            f"ì €ëŠ” AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤."
            f" ìš°ì„  ì§€ì›ìë¶„ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
        )

    def generateFirstFollowup(
            self,
            interviewId: int,
            topic: str,
            experienceLevel: str,
            academicBackground: str,
            questionId: int,
            answerText: str,
            userToken: str
    ) -> list[str]:
        print(f"ğŸ§  [repository] Generating intro follow-up questions for interviewId={interviewId},userToken={userToken}")

        # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = (
            f"ë„ˆëŠ” IT ê¸°ì—…ì˜ ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ ë©´ì ‘ìì˜ ê¸°ë³¸ì •ë³´(ì§ë¬´, ê²½ë ¥)ì™€ ìê¸°ì†Œê°œ ë‹µë³€, í•™ë ¥ ë°°ê²½ì„ ì°¸ê³ í•´ì„œ, ê´€ë ¨ëœ ê¼¬ë¦¬ ì§ˆë¬¸ 2ê°œë¥¼ ë§Œë“¤ì–´ì¤˜.\n\n"
            f"- ë©´ì ‘ìë¥¼ ë¶€ë¥¼ ë•Œ 'ì§€ì›ìë‹˜'ì´ë¼ê³  í•´"
            f"[ì§ë¬´]: {topic}"
            f"[ê²½ë ¥]: {experienceLevel}"
            f"[í•™ë ¥ ë°°ê²½]: {academicBackground}\n"
            f"[ì²« ì§ˆë¬¸ ë²ˆí˜¸]: {questionId}"
            f"[ìê¸°ì†Œê°œ ë‹µë³€]: {answerText}\n\n"
            f"ìš”ì²­ì‚¬í•­:\n"
            f"- ì§ˆë¬¸ì€ ì´ 2ê°œ\n"
            f"- ìê¸°ì†Œê°œ ë‚´ìš©ê³¼ í•™ë ¥ì— ê¸°ë°˜í•œ ê¶ê¸ˆí•œ ì ì„ ëª…í™•í•˜ê²Œ ì§ˆë¬¸í•´\n"
            f"- í•™ë ¥ì— ëŒ€í•œ ì§ˆë¬¸ì€ ëŒ€í•™êµ ì´ë¦„ì„ ë¬¼ì–´ë³´ì§€ ë§ê³ , ì–´ëŠ í•™ê³¼ë¥¼ ë‚˜ì™”ê³ , ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í–ˆëƒ ì´ëŸ°ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì¤˜"
            f"- ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ê³ , ì¤„ë°”ê¿ˆ(\\n)ìœ¼ë¡œ êµ¬ë¶„í•´ì¤˜\n"
            f"- ë²ˆí˜¸ ì—†ì´, ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ"
        )

        # GPT í˜¸ì¶œ
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—­í• ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        result_text = response.choices[0].message.content.strip()
        questions = [q.strip() for q in result_text.split("\n") if q.strip()]

        print(f"âœ… [repository] Follow-up questions generated: {questions}")
        return questions

    '''''
    # ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±
    def generateProjectFollowupQuestion(
            self,
            interviewId: int,
            jobCategory: int,
            experienceLevel: int,
            tech_stack: int,
            projectExperience: int,
            userToken: str
    ) -> list[str]:
        print(f"ğŸ“¡ [AI Server] Generating 5 questions for interviewId={interviewId}, userToken={userToken}")


        # ğŸ¯ í”„ë¡¬í”„íŠ¸ ì •ì˜
        prompt = (
            f"ë„ˆëŠ” ê¸°ìˆ  ë©´ì ‘ê´€ì´ì•¼. ë‹¤ìŒ ë©´ì ‘ì ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ 5ê°œë¥¼ ìƒì„±í•´ì¤˜.\n\n"
            f"[ì§ë¬´ ë¶„ì•¼]: {jobCategory}\n"
            f"[ê²½ë ¥ ìˆ˜ì¤€]: {mapped_experience}\n"
            f"[í•™ë ¥ ë°°ê²½]: {mapped_academic}\n"
            f"[ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ]: {mapped_tech}\n"
            
            f"- 'í”„ë¡œì íŠ¸ ê²½í—˜'ì´ ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ ë°˜ë“œì‹œ 1ê°œ í¬í•¨ë˜ì–´ì•¼ í•´\n"
            f"[í”„ë¡œì íŠ¸ ê²½í—˜]: {'ìˆìŒ' if projectExperience else 'ì—†ìŒ'}\n\n"
            f"ìš”ì²­ì‚¬í•­:\n"
            f"- ì§ˆë¬¸ì€ ì´ 5ê°œ\n"
            f"- ì§ˆë¬¸ì€ ì§§ê³  ëª…í™•í•˜ê²Œ\n"
            f"- ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ê³  ì„¤ëª…ì€ ìƒëµ\n"
            f"- ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ ì§ˆë¬¸ì„ êµ¬ë¶„í•´ì¤˜\n"
        )

        # ğŸ“¡ GPT-4 í˜¸ì¶œ
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” IT ê¸°ì—…ì˜ ì‹¤ì œ ë©´ì ‘ê´€ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        questions_text = response.choices[0].message["content"].strip()
        questions = [q.strip() for q in questions_text.split("\n") if q.strip()]

        return questions
'''''
    # ë©´ì ‘ ì¢…ë£Œ
    def end_interview(self,
                                session_id: str,
                                context: Dict[str, str],
                                questions: List[str],
                                answers: List[str]
                                ) -> Dict:
            # GPTë¥¼ ì‚¬ìš©í•´ ë©´ì ‘ ìš”ì•½ ìƒì„±
            joined_qna = "\n".join(
                [f"Q{i + 1}: {q}\nA{i + 1}: {a}" for i, (q, a) in enumerate(zip(questions, answers))]
            )

            context_summary = "\n".join([f"{k}: {v}" for k, v in context.items()])

            prompt = f"""
    ë„ˆëŠ” ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ëŠ” í•œ ì‚¬ìš©ìì˜ ì „ì²´ ë©´ì ‘ íë¦„ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ì´ì•¼.

    [ë©´ì ‘ì ì •ë³´]
    {context_summary}

    [ë©´ì ‘ ë‚´ìš©]
    {joined_qna}

    ë©´ì ‘ìì˜ ì „ì²´ì ì¸ íƒœë„, ê²½í—˜, ê°•ì ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ìš”ì•½ ë° í”¼ë“œë°±ì„ ìƒì„±í•´ì¤˜.
    """

            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ë©´ì ‘ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì£¼ëŠ” AI ì¸ì‚¬ë‹´ë‹¹ìì•¼."},
                    {"role": "user", "content": prompt.strip()}
                ],
                temperature=0.5
            )

            summary = response.choices[0].message["content"].strip()

            return {
                "session_id": session_id,
                "summary": summary,
                "message": "ë©´ì ‘ì´ ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
