import os
from typing import List, Dict

import openai

from interview.repository.interview_repository import InterviewRepository

class InterviewRepositoryImpl(InterviewRepository):
    openai.api_key = os.getenv("OPENAI_API_KEY")

    # ì²« ì§ˆë¬¸ ìƒì„±: ê³ ì¥ì§ˆë¬¸ "ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš”"
    def generateQuestions(
        self, interviewId: int, topic: str, experienceLevel: str, userToken: str
    ) -> str:
        print(f"[repository] Generating a single question from fine-tuned model for interviewId={interviewId}, userToken={userToken}")

        # ê³ ì •ì§ˆë¬¸
        # ìê¸°ì†Œê°œë¡œ ê°œì¸ì •ë³´ (ì´ë¦„ê³¼ ë‚˜ì´, í•™êµ ë“±ë“±) ì–»ê¸° -> ì´ ì •ë³´ëŠ” ë‹¤ìŒ ë‹µë³€ì— ì €ì¥
        return (
            f"{topic}ì˜ {experienceLevel}ë¶„ì•¼ì— ì§€ì›í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. "
            f"ì €ëŠ” AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤."
            f" ìš°ì„  ì§€ì›ìë¶„ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
        )

    def generateFirstFollowup(
            self,
            interviewId: int,
            topic: str,
            experienceLevel: str,
            academicBackground: str,
            questionId: int,
            answerText: str,
            userToken: str
    ) -> list[str]:
        print(f" [repository] Generating intro follow-up questions for interviewId={interviewId},userToken={userToken}")

        # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = (
            f"ë„ˆëŠ” IT ê¸°ì—…ì˜ ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ ë©´ì ‘ìì˜ ê¸°ë³¸ì •ë³´(ì§ë¬´, ê²½ë ¥)ì™€ ìê¸°ì†Œê°œ ë‹µë³€, í•™ë ¥ ë°°ê²½ì„ ì°¸ê³ í•´ì„œ, ê´€ë ¨ëœ ê¼¬ë¦¬ ì§ˆë¬¸ ë§Œë“¤ì–´ì¤˜.\n\n"
            f"- ë©´ì ‘ìë¥¼ ë¶€ë¥¼ ë•Œ 'ì§€ì›ìë‹˜'ì´ë¼ê³  í•´"
            f"[ì§ë¬´]: {topic}"
            f"[ê²½ë ¥]: {experienceLevel}"
            f"[í•™ë ¥ ë°°ê²½]: {academicBackground}\n"
            f"[ì²« ì§ˆë¬¸ ë²ˆí˜¸]: {questionId}"
            f"[ìê¸°ì†Œê°œ ë‹µë³€]: {answerText}\n\n"
            f"ìš”ì²­ì‚¬í•­:\n"
            f"- ì§ˆë¬¸ì€ ì´ 1ê°œ\n"
            f"- [ì§ë¬´], [ê²½ë ¥], [í•™ë ¥ ë°°ê²½] ê´€ë ¨ ì§ˆë¬¸ë§Œ í•˜ê³ , [í”„ë¡œì íŠ¸] ì§ˆë¬¸ì€ í•˜ì§€ë§ˆ"
            f"- ìê¸°ì†Œê°œ ë‚´ìš©ê³¼ í•™ë ¥ì— ê¸°ë°˜í•œ ê¶ê¸ˆí•œ ì ì„ ëª…í™•í•˜ê²Œ ì§ˆë¬¸í•´\n"
            f"- í•™ë ¥ì— ëŒ€í•œ ì§ˆë¬¸ì€ ëŒ€í•™êµ ì´ë¦„ì„ ë¬¼ì–´ë³´ì§€ ë§ê³ , ì–´ëŠ í•™ê³¼ë¥¼ ë‚˜ì™”ê³ , 'ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í–ˆìŠµë‹ˆê¹Œ?' ì´ëŸ°ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì¤˜"
            f"- ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ê³ , ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„í•´ì¤˜\n"
            f"- ë²ˆí˜¸ ì—†ì´, ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ"
        )

        # GPT í˜¸ì¶œ
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—­í• ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        result_text = response.choices[0].message.content.strip()
        questions = [q.strip() for q in result_text.split("\n") if q.strip()]

        print(f" [repository] Follow-up questions generated: {questions}")
        return questions

    # í”„ë¡œì íŠ¸ ì§ˆë¬¸: 3
    def generateProjectQuestion(
            self,
            interviewId: int,
            projectExperience: str,
            userToken: str
    ) -> list[str]:
        print(f"ğŸ“¡ [AI Server] Generating fixed project question for interviewId={interviewId}, userToken={userToken}")

        if projectExperience == "í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ":
            return ["ë‹¤ìŒ ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ì— ê´€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.\n ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ì…¨ë‚˜ìš”?"]
        else:
            return ["ë‹¤ìŒ ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ í˜¹ì€ ì§ë¬´ ê´€ë ¨ í™œë™ì— ê´€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.\n ì§ë¬´ì™€ ê´€ë ¨ëœ í™œë™ì„ í•´ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?"]


    # í”„ë¡œì íŠ¸ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±: 4
    def generateProjectFollowupQuestion(
            self,
            interviewId: int,
            topic: str,
            techStack: list[str],
            projectExperience: str,
            questionId: int,
            answerText: str,
            userToken: str,
    ) -> list[str]:

        print(f"ğŸ“¡ [AI Server] Generating 5 questions for interviewId={interviewId}, userToken={userToken}")

        # ğŸ¯ í”„ë¡¬í”„íŠ¸ ì •ì˜
        if projectExperience == "í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ":
            prompt = (
                "ë„ˆëŠ” ê¸°ìˆ  ë©´ì ‘ê´€ì´ì•¼. ë‹¤ìŒ ë©´ì ‘ìì˜ ì´ì „ ë‹µë³€ê³¼ ì§ˆë¬¸ IDë¥¼ ì°¸ê³ í•´ì„œ, ê·¸ì— ëŒ€í•œ ì‹¬í™” ì§ˆë¬¸ ë˜ëŠ” ê¼¬ë¦¬ ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´ì¤˜.\n\n"
                "[í”„ë¡œì íŠ¸ ê²½í—˜ ìœ ë¬´]: ìˆìŒ\n"
                "- ì´ì „ ì§ˆë¬¸ ID(questionId)ì™€ ë©´ì ‘ìì˜ ë‹µë³€(answerText)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ì„± ë†’ì€ í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•´ì•¼ í•´.\n\n"
                "ìš”ì²­ì‚¬í•­:\n"
                "- ë©´ì ‘ìëŠ” ì´ 1ê°œì˜ ì§ˆë¬¸ì„ ë°›ê²Œ ë©ë‹ˆë‹¤.\n"
                "- ì§ˆë¬¸ í•˜ë‚˜ â†’ ë‹µë³€ â†’ ë‹¤ìŒ ì§ˆë¬¸ ìˆœìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n"
                "- ì§€ê¸ˆì€ ê·¸ ì¤‘ ë‘ ë²ˆì§¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.\n"
                "- ì§ˆë¬¸ì€ ì§§ê³  ëª…í™•í•˜ê²Œ, ì„¤ëª… ì—†ì´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."
            )
        else:
            prompt = (
                "ë„ˆëŠ” ê¸°ìˆ  ë©´ì ‘ê´€ì´ì•¼. ë‹¤ìŒ ë©´ì ‘ìì˜ ì´ì „ ë‹µë³€ê³¼ ì§ˆë¬¸ IDë¥¼ ì°¸ê³ í•´ì„œ, ê·¸ì— ëŒ€í•œ ì‹¬í™” ì§ˆë¬¸ ë˜ëŠ” ê¼¬ë¦¬ ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´ì¤˜.\n\n"
                "[í”„ë¡œì íŠ¸ ê²½í—˜ ìœ ë¬´]: ì—†ìŒ\n"
                "- ì´ì „ ì§ˆë¬¸ ID(questionId)ì™€ ë©´ì ‘ìì˜ ë‹µë³€(answerText)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ì„± ë†’ì€ í›„ì† ì§ˆë¬¸ì„ ìƒì„±í•´ì•¼ í•´.\n\n"
                "ìš”ì²­ì‚¬í•­:\n"
                "- ë©´ì ‘ìëŠ” ì´ 1ê°œì˜ ì§ˆë¬¸ì„ ë°›ê²Œ ë©ë‹ˆë‹¤.\n"
                "- ì§ˆë¬¸ í•˜ë‚˜ â†’ ë‹µë³€ â†’ ë‹¤ìŒ ì§ˆë¬¸ ìˆœìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.\n"
                "- ì§€ê¸ˆì€ ê·¸ ì¤‘ ë‘ ë²ˆì§¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.\n"
                "- ì§ˆë¬¸ì€ ì§§ê³  ëª…í™•í•˜ê²Œ, ì„¤ëª… ì—†ì´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."
            )

        # ğŸ“¡ GPT-4 í˜¸ì¶œ
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—­í• ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        result_text = response.choices[0].message.content.strip()
        questions = [q.strip() for q in result_text.split("\n") if q.strip()]

        return questions

    # ë©´ì ‘ ì¢…ë£Œ
    def end_interview(self,
                                session_id: str,
                                context: Dict[str, str],
                                questions: List[str],
                                answers: List[str]
                                ) -> Dict:
            # GPTë¥¼ ì‚¬ìš©í•´ ë©´ì ‘ ìš”ì•½ ìƒì„±
            joined_qna = "\n".join(
                [f"Q{i + 1}: {q}\nA{i + 1}: {a}" for i, (q, a) in enumerate(zip(questions, answers))]
            )

            context_summary = "\n".join([f"{k}: {v}" for k, v in context.items()])

            prompt = f"""
    ë„ˆëŠ” ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ëŠ” í•œ ì‚¬ìš©ìì˜ ì „ì²´ ë©´ì ‘ íë¦„ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ì´ì•¼.

    [ë©´ì ‘ì ì •ë³´]
    {context_summary}

    [ë©´ì ‘ ë‚´ìš©]
    {joined_qna}

    ë©´ì ‘ìì˜ ì „ì²´ì ì¸ íƒœë„, ê²½í—˜, ê°•ì ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ìš”ì•½ ë° í”¼ë“œë°±ì„ ìƒì„±í•´ì¤˜.
    """

            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ë©´ì ‘ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì£¼ëŠ” AI ì¸ì‚¬ë‹´ë‹¹ìì•¼."},
                    {"role": "user", "content": prompt.strip()}
                ],
                temperature=0.5
            )

            summary = response.choices[0].message["content"].strip()

            return {
                "session_id": session_id,
                "summary": summary,
                "message": "ë©´ì ‘ì´ ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            }

