import os
from typing import List, Dict
from openai import AsyncOpenAI
from dotenv import load_dotenv

from interview.repository.interview_repository import InterviewRepository

load_dotenv()
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class InterviewRepositoryImpl(InterviewRepository):

    # ì²« ì§ˆë¬¸ ìƒì„±: ê³ ì¥ì§ˆë¬¸ "ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš”"
    def generateQuestions(
        self, interviewId: int, topic: str, experienceLevel: str, userToken: str
    ) -> str:
        print(f"[repository] Generating a single question from fine-tuned model for interviewId={interviewId}, userToken={userToken}")

        # ê³ ì •ì§ˆë¬¸
        # ìê¸°ì†Œê°œë¡œ ê°œì¸ì •ë³´ (ì´ë¦„ê³¼ ë‚˜ì´, í•™êµ ë“±ë“±) ì–»ê¸° -> ì´ ì •ë³´ëŠ” ë‹¤ìŒ ë‹µë³€ì— ì €ì¥
        return {
            "question": (
                f"{topic}ì˜ {experienceLevel} ë¶„ì•¼ì— ì§€ì›í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
                f" ì €ëŠ” AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤. "
                f"ìš°ì„  ì§€ì›ìë¶„ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤."),
            "questionId": 1  # ì‹¤ì œ DB ì €ì¥ ì‹œ IDë¡œ êµì²´
        }


    async def generateFirstFollowup(
            self,
            interviewId: int,
            topic: str,
            experienceLevel: str,
            academicBackground: str,
            companyName: str,
            questionId: int,
            answerText: str,
            userToken: str,
            context: str,
            summary: str,
    ) -> list[str]:
        print(f" [repository] Generating intro follow-up questions for interviewId={interviewId},userToken={userToken}")

        prompt = (
            f"ë„ˆëŠ” IT ê¸°ì—…ì˜ ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ ë©´ì ‘ìì˜ ê¸°ë³¸ ì •ë³´ì™€ ìê¸°ì†Œê°œ ë‹µë³€ì„ ì°¸ê³ í•´, ì§ë¬´Â·ê²½ë ¥Â·í•™ë ¥ ë°°ê²½ê³¼ ê´€ë ¨ëœ ê¼¬ë¦¬ ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´ì¤˜.\n\n"
            f"[ì§ë¬´]: {topic}\n"
            f"[ê²½ë ¥]: {experienceLevel}\n"
            f"[í•™ë ¥ ë°°ê²½]: {academicBackground}\n"
            f"[ì²« ì§ˆë¬¸ ë²ˆí˜¸]: {questionId}\n"
            f"[ìê¸°ì†Œê°œ ë‹µë³€]: {answerText}\n\n"
            f"[ì´ íšŒì‚¬ì˜ ì§ˆë¬¸ ìŠ¤íƒ€ì¼ ìš”ì•½]: {summary}\n"
            f"[ê³¼ê±° ìœ ì‚¬ ì§ˆë¬¸ ì˜ˆì‹œ]: {context}\n\n"
            f"ìš”ì²­ì‚¬í•­:\n"
            f"- ì§ˆë¬¸ì€ ë°˜ë“œì‹œ **ì§§ê³  ëª…í™•í•œ í•œ ë¬¸ì¥**ìœ¼ë¡œ ì‘ì„±í•  ê²ƒ\n"
            f"- **ë³µí•© ì§ˆë¬¸ ê¸ˆì§€**: í•˜ë‚˜ì˜ ì£¼ì œë§Œ ë¬¼ì–´ë³¼ ê²ƒ\n"
            f"- **ì„¤ëª…, ì¸ì‚¿ë§, ì¤„ë°”ê¿ˆ, ê¸°íƒ€ ë¬¸ì¥ í¬í•¨ ê¸ˆì§€**\n"
            f"- í•™ë ¥ ê´€ë ¨ ì§ˆë¬¸ ì‹œ, ëŒ€í•™ ì´ë¦„ì€ ë¬»ì§€ ë§ê³  ì „ê³µì´ë‚˜ ê³µë¶€í•œ ë‚´ìš©ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±\n"
            f"- **[í”„ë¡œì íŠ¸] ê´€ë ¨ ì§ˆë¬¸ì€ í•˜ì§€ ë§ ê²ƒ**\n"
            f"- ì¶œë ¥ì€ ì§ˆë¬¸ í•œ ë¬¸ì¥ë§Œ, ì•„ë¬´ ì„¤ëª…ë„ ë¶™ì´ì§€ ë§ê³  ì¶œë ¥í•  ê²ƒ"
        )

        # GPT í˜¸ì¶œ
        response = await client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—­í• ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )
        print(f" response type: {type(response)}")

        result_text = response.choices[0].message.content.strip()
        questions = [q.strip() for q in result_text.split("\n") if q.strip()]

        print(f" [repository] Follow-up questions generated: {questions}")
        print(f" returning questions: {questions}")
        return questions

    # í”„ë¡œì íŠ¸ ì§ˆë¬¸: 3
    def generateProjectQuestion(
            self,
            interviewId: int,
            projectExperience: str,
            userToken: str
    ) -> list[str]:
        print(f"ğŸ“¡ [AI Server] Generating fixed project question for interviewId={interviewId}, userToken={userToken}")

        if projectExperience == "í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ":
            return ["ë‹¤ìŒ ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ì— ê´€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.\n ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ì…¨ë‚˜ìš”?"]
        else:
            return ["ë‹¤ìŒ ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ í˜¹ì€ ì§ë¬´ ê´€ë ¨ í™œë™ì— ê´€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤.\n ì§ë¬´ì™€ ê´€ë ¨ëœ í™œë™ì„ í•´ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?"]


    # í”„ë¡œì íŠ¸ ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±: 4
    async def generateProjectFollowupQuestion(
            self,
            interviewId: int,
            topic: str,
            techStack: list[str],
            projectExperience: str,
            companyName : str,
            questionId: int,
            answerText: str,
            userToken: str,
            context: str,
            summary: str,
    ) -> list[str]:

        print(f"[AI Server] Generating 5 questions for interviewId={interviewId}, userToken={userToken}")

        # í”„ë¡¬í”„íŠ¸ ì •ì˜
        if projectExperience == "í”„ë¡œì íŠ¸ ê²½í—˜ ìˆìŒ":
            tech_stack_str = ", ".join(techStack)
            prompt = f"""
        ë„ˆëŠ” IT ê¸°ì—…ì˜ ì‹¤ì œ ë©´ì ‘ê´€ì´ì•¼.
        ë©´ì ‘ìì˜ ì´ì „ ë‹µë³€ê³¼ íšŒì‚¬ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë©´ì ‘ ìŠ¤íƒ€ì¼ì„ ë°”íƒ•ìœ¼ë¡œ,
        ë‹µë³€ íë¦„ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” í›„ì† ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì¤˜.

        [ì§ˆë¬¸ ID]: {questionId}
        [ë©´ì ‘ì ë‹µë³€]: {answerText}
        [ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ]: {tech_stack_str}
        [ì´ íšŒì‚¬ì˜ ì§ˆë¬¸ ìŠ¤íƒ€ì¼ ìš”ì•½]: {summary}
        [ê³¼ê±° ìœ ì‚¬ ì§ˆë¬¸ ì˜ˆì‹œ]: {context}

        ê·œì¹™:
        - ì§ˆë¬¸ì€ **ë°˜ë“œì‹œ ì§ì „ ë‹µë³€ì— ë…¼ë¦¬ì ìœ¼ë¡œ ì´ì–´ì§€ëŠ” í•œ ë¬¸ì¥**ì´ì–´ì•¼ í•¨
        - **"~í•œ ì  ìˆë‚˜ìš”?", "~í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"**ì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ í˜•íƒœ ê¶Œì¥
        - **"í”„ë¡œì íŠ¸ ê²½í—˜ì´ ìˆë‹¤ë©´..."**ì²˜ëŸ¼ ì¡°ê±´ì‹ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ì€ ê¸ˆì§€
        - ì§ˆë¬¸ì€ **ì§§ê³  ëª…í™•í•˜ê²Œ**, ì„¤ëª… ì—†ì´ ì¶œë ¥
        - ì‚¬ìš©í•œ ê¸°ìˆ (ìŠ¤íƒ)ì˜ í™œìš© ë°©ì‹, ì„ íƒ ì´ìœ , ë¬¸ì œ í•´ê²° ê²½í—˜ ë“±ìœ¼ë¡œ ì—°ê²°ë˜ë©´ ì¢‹ìŒ
        """

        else:
            tech_stack_str = ", ".join(techStack)
            prompt = f"""
        ë„ˆëŠ” IT ê¸°ì—…ì˜ ì‹¤ì œ ë©´ì ‘ê´€ì´ì•¼.
        ë©´ì ‘ìì˜ ë‹µë³€ê³¼ ê¸°ì—… ë©´ì ‘ ìŠ¤íƒ€ì¼ì— ë§ì¶°, ì§ë¬´ë‚˜ ê¸°ìˆ  í•™ìŠµ ê²½í—˜ì— ê¸°ë°˜í•œ
        ìì—°ìŠ¤ëŸ½ê³  êµ¬ì²´ì ì¸ ê¼¬ë¦¬ì§ˆë¬¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìƒì„±í•´ì¤˜.

        [ì§ˆë¬¸ ID]: {questionId}
        [ë©´ì ‘ì ë‹µë³€]: {answerText}
        [ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ]: {tech_stack_str}
        [ì´ íšŒì‚¬ì˜ ì§ˆë¬¸ ìŠ¤íƒ€ì¼ ìš”ì•½]: {summary}
        [ê³¼ê±° ìœ ì‚¬ ì§ˆë¬¸ ì˜ˆì‹œ]: {context}

        ê·œì¹™:
        - ì§ë¬´ ê´€ë ¨ í•™ìŠµ ê²½í—˜, í˜‘ì—… ê²½í—˜, ê¸°ìˆ  ìŠµë“ ë…¸ë ¥ì— ê¸°ë°˜í•œ ì§ˆë¬¸ì„ ìƒì„±í•  ê²ƒ
        - **"ê²½í—˜ì´ ì—†ë‹¤ë©´..."** ë˜ëŠ” ê°€ì •í˜• ì¡°ê±´ë¬¸ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ì€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ
        - ë°˜ë“œì‹œ **í•œ ë¬¸ì¥ì˜ ì‹¤ì œ ì§ˆë¬¸**ë§Œ ì¶œë ¥ (ì„¤ëª…, ì¤„ë°”ê¿ˆ ê¸ˆì§€)
        - ì‚¬ìš©í•œ ê¸°ìˆ (ìŠ¤íƒ)ì˜ í™œìš© ë°©ì‹, ì„ íƒ ì´ìœ , ë¬¸ì œ í•´ê²° ê²½í—˜ ë“±ìœ¼ë¡œ ì—°ê²°ë˜ë©´ ì¢‹ìŒ
        """

        # GPT-4 í˜¸ì¶œ
        response = await client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì§„ì§œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—­í• ì´ì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

        result_text = response.choices[0].message.content.strip()
        questions = [q.strip() for q in result_text.split("\n") if q.strip()]

        return questions

    # ë©´ì ‘ ì¢…ë£Œ
    async def end_interview(self,
                                session_id: str,
                                context: Dict[str, str],
                                questions: List[str],
                                answers: List[str]
                                ) -> Dict:
            # GPTë¥¼ ì‚¬ìš©í•´ ë©´ì ‘ ìš”ì•½ ìƒì„±
            joined_qna = "\n".join(
                [f"Q{i + 1}: {q}\nA{i + 1}: {a}" for i, (q, a) in enumerate(zip(questions, answers))]
            )

            context_summary = "\n".join([f"{k}: {v}" for k, v in context.items()])

            prompt = f"""
    ë„ˆëŠ” ë©´ì ‘ê´€ì´ì•¼. ì•„ë˜ëŠ” í•œ ì‚¬ìš©ìì˜ ì „ì²´ ë©´ì ‘ íë¦„ê³¼ ê·¸ì— ëŒ€í•œ ë‹µë³€ì´ì•¼.

    [ë©´ì ‘ì ì •ë³´]
    {context_summary}

    [ë©´ì ‘ ë‚´ìš©]
    {joined_qna}

    ë©´ì ‘ìì˜ ì „ì²´ì ì¸ íƒœë„, ê²½í—˜, ê°•ì ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ ìš”ì•½ ë° í”¼ë“œë°±ì„ ìƒì„±í•´ì¤˜.
    """

            response = await client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ë©´ì ‘ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì£¼ëŠ” AI ì¸ì‚¬ë‹´ë‹¹ìì•¼."},
                    {"role": "user", "content": prompt.strip()}
                ],
                temperature=0.5
            )

            summary = response.choices[0].message["content"].strip()

            return {
                "session_id": session_id,
                "summary": summary,
                "message": "ë©´ì ‘ì´ ì„±ê³µì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "success": True
            }